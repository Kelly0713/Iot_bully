import cv2
import time
import pyttsx3
import threading
import speech_recognition as sr
from ultralytics import YOLO

# åˆå§‹åŒ–èªéŸ³å¼•æ“
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# è¼‰å…¥ YOLOv8 pose æ¨¡å‹
model = YOLO('yolov8n-pose.pt')

# é–‹å•Ÿæ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
    exit()

print("ğŸ”´ ä½¿ç”¨ YOLOv8 Pose åµæ¸¬éœ¸å‡Œï¼ˆå«èªéŸ³é—œéµå­—ï¼‰ï¼ŒæŒ‰ Q çµæŸ")

# åˆå§‹åŒ–è­¦å ±å†·å»æ©Ÿåˆ¶
last_alarm_time = 0
cooldown = 5

# âœ… é—œéµå­—æ¸…å–®ï¼ˆå¯è‡ªè¡Œæ“´å……ï¼‰
bully_keywords = ["å¹¹ä½ å¨˜æ©Ÿæ°", "å¹¹ä½ å¨˜", "å¹¹", "å»¢ç‰©", "å»æ­»", "ä½ å¾ˆçˆ›", "æ­»è‚¥è±¬"]

# åˆå§‹åŒ–èªéŸ³è¾¨è­˜å™¨
recognizer = sr.Recognizer()
mic = sr.Microphone()
audio_last_alarm_time = 0

def speak_warning():
    engine.say("å·²åµæ¸¬åˆ°éœ¸å‡Œè¡Œç‚ºï¼Œè«‹åœæ­¢")
    engine.runAndWait()

def check_bullying(keypoints):
    for person in keypoints:
        if len(person) >= 6:
            left_shoulder = person[5]
            right_shoulder = person[6]
            if left_shoulder[1] > 0 and right_shoulder[1] > 0:
                diff = abs(left_shoulder[1] - right_shoulder[1])
                if diff > 60:
                    return True
    return False

# âœ… èƒŒæ™¯èªéŸ³ç›£è½èˆ‡é—œéµå­—è¾¨è­˜
def audio_monitor():
    global audio_last_alarm_time
    with mic as source:
        recognizer.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ èªéŸ³ç›£è½ä¸­...")

        while True:
            try:
                audio = recognizer.listen(source, timeout=3)
                text = recognizer.recognize_google(audio, language="zh-TW")
                print(f"ğŸ—£ï¸ åµæ¸¬èªéŸ³å…§å®¹ï¼š{text}")

                for keyword in bully_keywords:
                    if keyword in text:
                        now = time.time()
                        if now - audio_last_alarm_time > cooldown:
                            print("ğŸš¨ èªéŸ³åµæ¸¬åˆ°éœ¸å‡Œé—œéµå­—ï¼")
                            speak_warning()
                            audio_last_alarm_time = now
                        break

            except sr.WaitTimeoutError:
                continue
            except sr.UnknownValueError:
                continue
            except Exception as e:
                print(f"âŒ èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š{e}")
                continue

# ğŸ” å•Ÿå‹•èªéŸ³åµæ¸¬ç‚ºèƒŒæ™¯åŸ·è¡Œç·’
audio_thread = threading.Thread(target=audio_monitor, daemon=True)
audio_thread.start()

# ğŸ” ä¸»å¾ªç’°ï¼šè¦–è¦ºåµæ¸¬éœ¸å‡Œå§¿å‹¢
while True:
    ret, frame = cap.read()
    if not ret or frame is None:
        print("âš ï¸ è®€å–ç•«é¢å¤±æ•—ï¼Œç•¥éæ­¤å¹€")
        continue

    try:
        results = model.predict(source=frame, conf=0.5, task='pose', verbose=False)
        keypoints_list = results[0].keypoints.xy.cpu().numpy()
        annotated_frame = results[0].plot()

        if check_bullying(keypoints_list):
            now = time.time()
            if now - last_alarm_time > cooldown:
                print("ğŸš¨ åµæ¸¬åˆ°å¯èƒ½çš„è‚¢é«”éœ¸å‡Œè¡Œç‚ºï¼")
                speak_warning()
                last_alarm_time = now

            cv2.putText(
                annotated_frame,
                "ğŸš¨ Bullying Detected!",
                (30, 50),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.2,
                (0, 0, 255),
                3
            )

        cv2.imshow("Bullying Detection", annotated_frame)

    except Exception as e:
        print(f"âŒ æ¨è«–æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        continue

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ğŸ”š çµæŸè³‡æº
cap.release()
cv2.destroyAllWindows()
